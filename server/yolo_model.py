import logging
import sys, os
import numpy as np
import cv2
from model import model
from time import time
from openvino.inference_engine import IECore
from object_detection import get_objects, filter_objects, put_highlighted_text, perf_counter, Mode, Modes, ModeInfo

logging.basicConfig(format="[ %(levelname)s ] %(message)s", level=logging.INFO, stream=sys.stdout)
log = logging.getLogger()

class yolo_model(model):
    def __init__(self, model, device = "MYRIAD", labels=None, prob_threshold=0.5, currentmode=Modes.MIN_LATENCY, keep_aspect_ratio=True, iou_threshold=0.4, raw_output_message=False):
        super().__init__()
        log.info("Initialising yolo model")
        log.info("Creating Inference Engine...")
        ie = IECore()

        config_user_specified = {}
        config_min_latency = {}

        devices_nstreams = {}

        self.prob_threshold = prob_threshold
        self.keep_aspect_ratio = keep_aspect_ratio
        self.iou_threshold = iou_threshold
        self.raw_output_message = raw_output_message
        self.currentmode = currentmode

        # -------------------- 2. Reading the IR generated by the Model Optimizer (.xml and .bin files) --------------------
        log.info("Loading network")
        ie = IECore()
        self.net =  ie.read_network(model, os.path.splitext(model)[0] + ".bin")

        # ---------------------------------------------- 4. Preparing inputs -----------------------------------------------
        log.info("Preparing inputs")
        self.input_blob = next(iter(self.net.input_info))
        self.out_blob = next(iter(self.net.outputs))

        # Read and pre-process input images
        if self.net.input_info[self.input_blob].input_data.shape[1] == 3:
            input_height, input_width = self.net.input_info[self.input_blob].input_data.shape[2:]
            nchw_shape = True
        else:
            input_height, input_width = self.net.input_info[self.input_blob].input_data.shape[1:3]
            nchw_shape = False

        if labels:
            with open(labels, 'r') as f:
                self.labels_map = [x.strip() for x in f]
        else:
            self.labels_map = None

        self.mode = Mode(self.currentmode)
        wait_key_time = 1

        self.mode_info = { self.mode.current: ModeInfo() }

        # ----------------------------------------- 5. Loading model to the plugin -----------------------------------------
        log.info("Loading model to the plugin")
        self.exec_nets = {}

        self.exec_nets[Modes.USER_SPECIFIED] = ie.load_network(network=self.net, device_name=device,
                                                          config=config_user_specified)
        self.exec_nets[Modes.MIN_LATENCY] = ie.load_network(network=self.net, device_name=device.split(":")[-1].split(",")[0],
                                                       config=config_min_latency,
                                                       num_requests=1)

    def process(self, frame):
        if frame is None:
            return None
        n, c, input_height, input_width = self.net.input_info["input_1"].input_data.shape
        #image = cv2.imread(self.input[0])
        if frame.shape[:-1] != (input_height, input_width):
            #log.warning("Image {} is resized from {} to {}".format(self.input[0], image.shape[:-1], (h, w)))
            frame = cv2.resize(frame, (input_width, input_height))
            frame = frame.transpose((2, 0, 1))  # Change data layout from HWC to CHW

        start_time = time()

        # ----------------------------------------------- 6. Doing inference -----------------------------------------------
        output = self.exec_nets[self.mode.current].infer(inputs={self.input_blob: [frame]})
        #output = output[self.out_blob]

        objects = get_objects(output, self.net, (input_height, input_width), frame.shape[:-1], self.prob_threshold,
                              self.keep_aspect_ratio)
        objects = filter_objects(objects, self.iou_threshold, self.prob_threshold)
        log.info(f"found {len(objects)} obj")

        if len(objects) and self.raw_output_message:
            log.info(" Class ID | Confidence | XMIN | YMIN | XMAX | YMAX | COLOR ")


        frame = frame.transpose((1, 2, 0))
        origin_im_size = frame.shape[:-1]
        for obj in objects:
            # Validation bbox of detected object
            obj['xmax'] = min(obj['xmax'], origin_im_size[1])
            obj['ymax'] = min(obj['ymax'], origin_im_size[0])
            obj['xmin'] = max(obj['xmin'], 0)
            obj['ymin'] = max(obj['ymin'], 0)
            color = (min(obj['class_id'] * 12.5, 255),
                     min(obj['class_id'] * 7, 255),
                     min(obj['class_id'] * 5, 255))
            det_label = self.labels_map[obj['class_id']] if self.labels_map and len(self.labels_map) >= obj['class_id'] else \
                str(obj['class_id'])

            if self.raw_output_message:
                log.info(
                    "{:^9} | {:10f} | {:4} | {:4} | {:4} | {:4} | {} ".format(det_label, obj['confidence'],
                                                                              obj['xmin'], obj['ymin'], obj['xmax'],
                                                                              obj['ymax'],
                                                                              color))

            cv2.rectangle(frame, (obj['xmin'], obj['ymin']), (obj['xmax'], obj['ymax']), color, 2)
            cv2.putText(frame,
                        "#" + det_label + ' ' + str(round(obj['confidence'] * 100, 1)) + ' %',
                        (obj['xmin'], obj['ymin'] - 7), cv2.FONT_HERSHEY_COMPLEX, 0.6, color, 1)

        # Draw performance stats over frame
        if self.mode_info[self.mode.current].frames_count != 0:
            fps_message = "FPS: {:.1f}".format(self.mode_info[self.mode.current].frames_count / \
                                               (perf_counter() - self.mode_info[self.mode.current].last_start_time))
            self.mode_info[self.mode.current].latency_sum += perf_counter() - start_time
            latency_message = "Latency: {:.1f} ms".format((self.mode_info[self.mode.current].latency_sum / \
                                                          self.mode_info[self.mode.current].frames_count) * 1e3)

            put_highlighted_text(frame, fps_message, (15, 20), cv2.FONT_HERSHEY_COMPLEX, 0.75, (200, 10, 10), 2)
            put_highlighted_text(frame, latency_message, (15, 50), cv2.FONT_HERSHEY_COMPLEX, 0.75, (200, 10, 10), 2)

        mode_message = "{} mode".format(self.mode.current.name)
        #put_highlighted_text(frame, mode_message, (10, int(origin_im_size[0] - 20)),
        #                     cv2.FONT_HERSHEY_COMPLEX, 0.75, (10, 10, 200), 2)

        for mode_value in self.mode_info.keys():
            log.info("")
            log.info("Mode: {}".format(mode_value.name))

            end_time = self.mode_info[mode_value].last_end_time if mode_value in self.mode_info \
                                                              and self.mode_info[mode_value].last_end_time is not None \
                                                           else perf_counter()
            log.info("FPS: {:.1f}".format(self.mode_info[mode_value].frames_count / \
                                          (end_time - self.mode_info[mode_value].last_start_time)))
            log.info("Latency: {:.1f} ms".format((self.mode_info[mode_value].latency_sum / \
                                                 (1e-5+self.mode_info[mode_value].frames_count) * 1e3)))

        return frame
